{
  "query_helping": {
    "precision": 1.0,
    "recall": 0.9090909090909091,
    "f1-score": 0.9523809523809523,
    "support": 11
  },
  "query_infoattend_organisation": {
    "precision": 0.9354838709677419,
    "recall": 1.0,
    "f1-score": 0.9666666666666666,
    "support": 29
  },
  "affirm": {
    "precision": 0.925,
    "recall": 0.8409090909090909,
    "f1-score": 0.8809523809523809,
    "support": 44
  },
  "bye": {
    "precision": 0.8461538461538461,
    "recall": 0.7857142857142857,
    "f1-score": 0.8148148148148148,
    "support": 14
  },
  "thank": {
    "precision": 0.8571428571428571,
    "recall": 1.0,
    "f1-score": 0.923076923076923,
    "support": 24
  },
  "query_organisation": {
    "precision": 1.0,
    "recall": 1.0,
    "f1-score": 1.0,
    "support": 10
  },
  "greet": {
    "precision": 0.896551724137931,
    "recall": 0.896551724137931,
    "f1-score": 0.896551724137931,
    "support": 29
  },
  "micro avg": {
    "precision": 0.9130434782608695,
    "recall": 0.9130434782608695,
    "f1-score": 0.9130434782608695,
    "support": 161
  },
  "macro avg": {
    "precision": 0.9229046140574823,
    "recall": 0.9188951442646024,
    "f1-score": 0.9192062088613814,
    "support": 161
  },
  "weighted avg": {
    "precision": 0.9145752464325896,
    "recall": 0.9130434782608695,
    "f1-score": 0.9120042368489573,
    "support": 161
  }
}